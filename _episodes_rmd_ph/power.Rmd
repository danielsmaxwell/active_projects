---
title: "Effect Size and Power (Instructional Worksheet)"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#$\color{blue}{\text1.1}$ Measures of Effect Size

We will go through and calculate the effect size using the various methods for the different statistical tests we have learned about in the last couple of modules. We will use the same datasets that we used in previous modules so that we can examine the effect size for the tests that we previously ran and see how that influences our conclusions.

We will calculate each effect size using two different methods. First, directly using the equation from the textbook, and second using a function in the *pwr* package. Remember that in order to use the *pwr* package we first have to install the package and then load it using the *library(pwr)* command. 


###$\color{blue}{\text1.1a}$ Two Sample T-test

For the two sample t-test in module 12, we were interested in the mean weight post study of patients that were given the cognitive behavioral treatment versus the control treatment, from the *anorexia* dataset. We concluded that the mean weight post study was significantly different for the patients with the different treatments. In fact, we figured out that the mean weight post study for those with the cognitive behavioral treatment was significantly higher than that for the control group. 

So now, we are interested in the effect size for this difference. Is the effect size large enough that it would be worth it for someone to change the patients' treatment?

####Cohen's *d*

The formula for Cohen's *d* is as follows:
$$d = (M_1 - M_2) / S_{DV}$$

$M_1$ and $M_2$ refers to the mean of the two samples

$S_{DV}$ refers to the standard deviation of the dependent variable for all samples

```{r eval = FALSE}
M1 = mean(anorexia$Postwt[anorexia$Treat == "CBT"])
M2 = mean(anorexia$Postwt[anorexia$Treat == "Cont"])
SDV = sd(anorexia$Postwt[anorexia$Treat == "CBT" | anorexia$Treat == "Cont"])
d = (M1-M2)/SDV
```
Our results give us a Cohen's *d* value of 0.6368. Using the guidelines from the textbook, we conclude that this is a medium effect. 

####Effect size *r*

The formula for the effect size *r* is as follows:
$$r = sqrt(t^2/(t^2 + df))$$
$t^2$ refers to t-statistic calculated from the t-test

$df$ refers to the degrees of freedom of the t-test

```{r eval = FALSE}
ttest <- t.test(anorexia$Postwt[anorexia$Treat== "CBT"], anorexia$Postwt[anorexia$Treat== "Cont"])
t <- ttest$statistic #t statistic
df <- ttest$parameter #degrees of freedom
r <- sqrt(t^2/(t^2 + df))
```
Our results give us an effect size *r* value of 0.353. Using the guidelines from the textbook, we conclude, again, that this is a medium effect. 


###$\color{blue}{\text1.1b}$ ANOVA *F* Tests

For the ANOVA analysis in module 13, we were again interested in the mean weight post study of patients who were given various treatments, from the *anorexia* dataset. We concluded that there was a significant difference in mean weight post study between at least two of the different treatments.

Again, we are interested in the effect size for this difference. Is the effect size large enough that it would be worth it to change treatments?

####Effect size $\eta$
The formula for the effect size $\eta$ is as follows:
$$\eta = sqrt(SS_{bet}/SS_{tot})$$
$SS{bet}$ refers to the sum of squares between samples (i.e., sum of squares for the treatment)
$SS{tot}$ refers to the total sum of squares (i.e., sum of squares for the treatment and residuals combined)

```{r eval = FALSE}
a <- aov(anorexia$Postwt ~ anorexia$Treat)
r <- summary(a)
SS_bet <- r[[1]]$`Sum Sq`[1] #sum of squares for diet
SS_with <- r[[1]]$`Sum Sq`[2] #sum of squares for residuals
SS_tot <- SS_bet + SS_with
eta <- sqrt(SS_bet/SS_tot)
```
Our results give us an effect size $\eta$ value of 0.4477. Using the guidelines from the textbook, we conclude that this is a large effect.


###$\color{blue}{\text1.1c}$ Chi-square Tests
For the Chi-square Tests in module 15, we used our own clinical trial data to (1) see if our data follows the expected distribution and (2) test for independence between two or more variables.

We are interested in the effect size for our chi-square statistic - is the difference meaningful in practical terms?
We use a different statistic depending on the number of variables of interest.

####Goodness of Fit Test (One Variable)
The formula for the effect size $r$ is as follows:
$$r=sqrt(\chi^2/((N)(c-1))$$
$\chi^2$ refers to the chi-squared statistic
$N$ refers to the total sample size
$c$ refers to the number of categories

```{r eval = FALSE}
trial <- data.frame(outcome = c("benefit", "noeffect"), freq = c(705, 224))
chi <- chisq.test(trial$freq, p = c(0.75, 0.25))
N <- 929
c <- 2
chistat <- chi$statistic

r <- sqrt(chistat/(N*(c-1)))
```
Our results give us an effect size $r$ value of 0.021. Using the guidelines from the textbook, we conclude that this is a small effect.

Using the *pwr* package, we will use the *ES.w1()* function. This function requires two parameters, the probabilities for your data, and the probabilities for the expected distribution. 

```{r eval = FALSE}
ES.w1(c(705/929,224/929), c(0.75,0.25))
```


####Test for Independence (two-variable)
The effect size statistics for the test of independence depends on the number of categories on each variable. 
In module 15, we had 2 categories on 2 variables. In this situation we use $\phi$ as our effect size statistic.
The formula for the effect size $\phi$ is as follows:
$$\phi = sqrt(\chi^2/N)$$

$\chi^2$ refers to the chi-squared statistic
$N$ refers to the total sample size

```{r eval = FALSE}
trial$surv <- c(448, 103)
tab <- xtabs(cbind(freq, surv) ~ outcome, trial)
chi <- summary(tab)
N <- 929
chi_st <- chi$statistic
phi <- sqrt(chi_st/N)
```
Our results give us an effect size $\phi$ value of 0.0797. Using the guidelines from the textbook, we conclude that this is a small effect.


If we have more than 2 categories for each variable, we instead use Cramer's *V* as our effect size statistics.
Let's suppose that we also have patients who were negatively affected by the clinical trial. Supposer there are 97 patients who had a negative outcome, and 78 of these patients survived for the next year. First, add this information to your data frame and then rerun your chi-squared analysis. 

```{r eval = FALSE}
trial2 <- data.frame(outcome = c("benefit", "noeffect", "negative"), freq = c(705, 224, 97), surv = c(448, 103, 78))
tab2 <- xtabs(cbind(freq, surv) ~ outcome, trial2)
chi2 <- summary(tab)
chi_st2 <- chi2$statistic
```
In this situation, we will use Cramer's *V* as our effect size statistic. The formula is as follows:
$$V = sqrt(\phi^2/(the\ smaller\ of\ R\ or\ C)-1))$$
$R$ is the number of rows
$C$ is the number of columns
$\phi$ is calculated from the formula above


So, first lets calculate $\phi$ and then we can calculate *V*.

```{r eval = FALSE}
N <- 929
chi_st2 <- chi$statistic
phi <- sqrt(chi_st/N)
phi2 <- phi^2
#R = 3, C = 3 - 3 rows and 3 columns
V <- sqrt(phi2/(3-1))
```
Our results give us an effect size $V$ value of 0.0564. Using the guidelines from the textbook, we conclude that this is a small effect.


#$\color{blue}{\text1.2}$ Power

Once we have the effect size statistic, we can calculate power. Recall that power is when we correctly reject the null hypothesis that is in fact false. Ideally a power > 80% is desired.

####Power for 2-sample t-test with unequal sample size

We will use the function *pwr.t2n.test()* to calculate power. We will use the sample size, and Cohen's effect size (*d*) from above to calculate power. We will use a significance level of 5% (type 1 error probability).

```{r eval = FALSE}
pwr.t2n.test(n1=220,n2=120,d=d,sig.level=0.05,alternative="two.sided")
```
We have a power value of 0.9999 or 99.99%.


We can also calculate a power value for the chi-squared test (goodness of fit test), with effect size *r*.

```{r eval = FALSE}
pwr.chisq.test(w=r,N=2,df=1,sig.level=0.05,power=NULL)
```
For this test, our power is 0.05 or 5%.



